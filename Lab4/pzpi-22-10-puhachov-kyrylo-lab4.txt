Міністерство освіти та науки України
Харківський національний університет радіоелектроніки




Кафедра програмної інженерії



ЗВІТ
до лабораторної роботи №4 з дисципліни
«Архітектура програмного забезпечення»
На тему: «Масштабування бекенда»



Виконав:
ст. гр. ПЗПІ-22-10
Пугачов Кирило Вадимович

Перевірив:
ас. кафедри ПІ
Дашенков Дмитро Сергійович





Харків 2025
 
1.	Мета роботи


Метою лабораторної роботи є вивчення способів масштабування серверної частини програмної системи в умовах зростаючого навантаження. У рамках роботи необхідно:
•	розгорнути серверну частину застосунку та базу даних за допомогою Docker і Docker Compose;
•	реалізувати можливість масштабування серверного застосунку;
•	підключити клієнтські інструменти для навантажувального тестування (Locust);
•	виконати тести для оцінки стійкості системи до високої кількості одночасних запитів;
•	проаналізувати результати, визначити вузькі місця продуктивності;
•	сформулювати висновки щодо ефективності масштабування.
У результаті виконання лабораторної роботи набуваються практичні навички роботи з контейнеризацією застосунків, конфігуруванням docker-compose та базовим навантажувальним тестуванням веб-сервісів.


2.	Dockerfile


Для контейнеризації серверної частини програмної системи, розробленої на платформі ASP.NET Core (.NET 5.0), було створено власний Dockerfile, який реалізує двоетапну збірку — спочатку публікація застосунку, потім запуск з мінімального середовища виконання.

# Етап 1: Побудова застосунку
FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build
WORKDIR /app

# Копіювання файлів проєкту та відновлення залежностей
COPY Bridges/Bridges.csproj ./Bridges/
RUN dotnet restore ./Bridges/Bridges.csproj

# Копіювання решти коду та публікація
COPY Bridges/. ./Bridges/
WORKDIR /app/Bridges
RUN dotnet publish -c Release -o /app/publish

# Етап 2: Запуск зображення на основі runtime
FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS runtime
WORKDIR /app
COPY --from=build /app/publish .

ENTRYPOINT ["dotnet", "Bridges.dll"]

Пояснення:
	Перший етап (build) виконує збірку проєкту з використанням повного SDK-образу.
	Другий етап (runtime) формує легкий контейнер для запуску, який містить лише необхідне середовище виконання (aspnet:5.0).
Використовується ENTRYPOINT для запуску зібраного .dll файлу.
Такий підхід дозволяє мінімізувати розмір кінцевого образу, розділити логіку побудови і виконання, а також спрощує подальше розгортання через docker-compose.


3.	Docker Compose


Для одночасного розгортання бекенда та бази даних було використано docker-compose.yml, що дозволяє підняти всю інфраструктуру одним командним рядком. У конфігурації визначено два сервіси: app (серверна частина) та db (PostgreSQL).

version: '3.9'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - db
    ports:
      - "5000:80"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ConnectionStrings__DefaultConnection=Host=db;Port=5432;Database=bridgesdb;Username=postgres;Password=secret

  db:
    image: postgres:15
    environment:
      POSTGRES_DB: bridgesdb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

volumes:
  pgdata:


Ключові елементи:
	app: збирається з локального Dockerfile. При запуску отримує змінну середовища з рядком підключення до бази даних.
	db: стандартний образ PostgreSQL. Для збереження даних між перезапусками використовується іменований том pgdata.
	depends_on: гарантує, що база даних буде запущена раніше за застосунок, однак не забезпечує готовність до з’єднання — тому в коді також застосовано EnableRetryOnFailure.
Запуск:
Запуск сервісів виконується однією командою:
docker-compose up --build
Для зупинки і очищення ресурсів:
docker-compose down -v

 


4.	Навантажувальне тестування (Locust)


Для перевірки стійкості системи до високих навантажень було використано інструмент Locust, який дозволяє моделювати поведінку великої кількості користувачів, що одночасно взаємодіють з API.
4.1. Конфігурація locustfile.py
from locust import HttpUser, task, between

class BridgeUser(HttpUser):
    wait_time = between(1, 3)

    @task(3)
    def get_bridges(self):
        self.client.get("/api/bridges")

    @task(1)
    def get_sensors(self):
        self.client.get("/api/sensors")
У тесті моделюється типова активність: запити до списку мостів (/api/bridges) та сенсорів (/api/sensors).
4.2. Запуск Locust
locust -f locustfile.py --host=http://localhost:5000
Після запуску Locust стає доступним за адресою:
http://localhost:8089
Тут задаються параметри:
	кількість користувачів (наприклад, 100)
	швидкість генерації запитів (наприклад, 10 користувачів/сек)
4.3. Результати тестування
На піку навантаження:
	Кількість одночасних користувачів: 100
	Частота запитів: 10 користувачів/сек
	Час роботи тесту: 2 хвилини
	Середній час відповіді: ~150–250 мс
	% помилок: 0%
	Максимальний час відповіді: до 600 мс при піковому навантаженні
Система впоралась із навантаженням без падінь або таймаутів. Завдяки використанню EnableRetryOnFailure та контейнеризації всі сервіси залишались стабільними.

 


5.	Висновок


У ході лабораторної роботи було реалізовано масштабовану архітектуру серверного застосунку з використанням Docker і Docker Compose. Серверна частина була контейнеризована, а база даних PostgreSQL налаштована як окремий сервіс у загальній інфраструктурі.
Було проведено навантажувальне тестування за допомогою інструмента Locust, що дозволило оцінити продуктивність системи при великій кількості одночасних запитів. За результатами тестування система продемонструвала стабільну роботу без помилок, із допустимими значеннями часу відповіді навіть на піковому навантаженні.
Контейнеризований підхід у поєднанні з правильно налаштованим рядком підключення, обробкою повторних спроб та використанням вбудованих механізмів EF Core зробив застосунок гнучким, переносимим і готовим до масштабування.

